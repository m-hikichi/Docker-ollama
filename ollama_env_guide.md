# Ollama 環境変数リファレンス

## 1) パフォーマンス／並列・スレッド制御

### `OLLAMA_NUM_PARALLEL`

* **用途**: 単一モデルが同時に処理できる**並列リクエスト数**の上限。
* **デフォルト**: 環境により自動（概ね `1〜4` の範囲）。
* **設定値**: `1` 以上の整数（推奨 1〜4）。
* **使用例**

  ```bash
  export OLLAMA_NUM_PARALLEL=4
  ```
* **シナリオ**: 同一モデルに同時アクセスが来る API サーバでスループットを上げたい。
* **注意**: 値を上げるほど RAM/VRAM 消費とコンテンドが増える。コア数やVRAMに見合った値に。

---

### `OLLAMA_MAX_LOADED_MODELS`

* **用途**: **同時にメモリ常駐できるモデル数**の上限。超えると未使用モデルをアンロード。
* **デフォルト**: 自動（例: GPU 環境で GPU 数×3 / CPU のみで 3 など）。
* **設定値**: `1` 以上の整数（`0` は自動判断に委ねる実装もあり）。
* **使用例**

  ```bash
  export OLLAMA_MAX_LOADED_MODELS=2
  ```
* **シナリオ**: 複数モデルを切替利用し、ロード待ちを減らしたい。
* **注意**: 各モデルのフットプリントを合算。過大設定は OOM やスワップの原因。

---

### `OLLAMA_MAX_QUEUE`

* **用途**: 並列数を超過したリクエストの**待ち行列長**。超過は 503 で拒否。
* **デフォルト**: `512`
* **設定値**: `0` 以上の整数（`0` はキューなし＝即 503）。
* **使用例**

  ```bash
  export OLLAMA_MAX_QUEUE=100
  ```
* **シナリオ**: スパイク（瞬間的高負荷）をバッファしたい。
* **注意**: キューを長くしすぎると**待ち時間が長大**になりクライアント側でタイムアウト。

---

### `OLLAMA_NUM_THREADS`（CPU 実行時）

* **用途**: CPU 推論時の**スレッド数**。未設定時は論理コア数などで自動。
* **デフォルト**: 自動
* **設定値**: `1` 以上の整数
* **使用例**

  ```bash
  export OLLAMA_NUM_THREADS=8
  ```
* **シナリオ**: CPU サーバで並列ベクトル化/スレッディングを明示制御したい。
* **注意**: スレッド過多はスレッシングや文脈長大時のキャッシュ競合を招く場合あり。

---

### `OLLAMA_FLASH_ATTENTION`

* **用途**: **Flash Attention** による高速化（対応 GPU/実装で有効）。
* **デフォルト**: 無効
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_FLASH_ATTENTION=1
  ```
* **シナリオ**: Apple Silicon / NVIDIA CUDA 環境で**生成速度向上**を狙う。
* **注意**: 非対応 GPU / CPU では効果なし。

---

### `OLLAMA_SCHED_SPREAD`

* **用途**: **複数 GPU** にモデルロードや推論を**分散**するスケジューリング。
* **デフォルト**: 無効
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_SCHED_SPREAD=1
  ```
* **シナリオ**: 2 枚以上の GPU を**均等活用**してスループット向上。
* **注意**: 単一巨大モデルは 1GPU に収まらないと性能が不安定になることも。

---

### `OLLAMA_INTEL_GPU`（実験的）

* **用途**: **Intel GPU** の実験的サポートを試す。
* **デフォルト**: 無効
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_INTEL_GPU=1
  ```
* **シナリオ**: Arc/内蔵 GPU での実験運用。
* **注意**: 安定性・性能は保証されない。検証環境でのみ推奨。

---

### `OLLAMA_LLM_LIBRARY`

* **用途**: 使用する**LLM 実行ライブラリ**を明示指定（自動検出を上書き）。
* **デフォルト**: 自動
* **設定値**: 例）`cpu` / `cpu_avx2` / `cuda_v12` / `rocm_v6` など
* **使用例**

  ```bash
  export OLLAMA_LLM_LIBRARY=cuda_v12
  ```
* **シナリオ**: 自動判定が不適切な環境で**バックエンド固定**したい。
* **注意**: 実行ログに「Dynamic LLM libraries」の候補が出る。存在しない名称は無視/失敗。

---

## 2) メモリ／キャッシュ・保存

### `OLLAMA_MAX_VRAM`

* **用途**: 1GPU あたり Ollama が使用する **VRAM 上限（バイト）**。
* **デフォルト**: 制限なし
* **設定値**: バイト数（例：8GB → `8589934592`）
* **使用例**

  ```bash
  export OLLAMA_MAX_VRAM=17179869184  # 16GB
  ```
* **シナリオ**: 他プロセスと VRAM 共用、誤検出対策。
* **注意**: 厳しすぎる上限は**GPU常駐不可→CPUオフロード**で低速化の原因。

---

### `OLLAMA_GPU_OVERHEAD`

* **用途**: **各 GPU の予約 VRAM**（バイト）。計算上この分は使用しない。
* **デフォルト**: `0`
* **設定値**: バイト数
* **使用例**

  ```bash
  export OLLAMA_GPU_OVERHEAD=1073741824  # 1GB
  ```
* **シナリオ**: ディスプレイ/他アプリ分の VRAM を**常に残す**。
* **注意**: 一部 OS では自動的に数百 MB を控除。二重控除に注意。

---

### `OLLAMA_KEEP_ALIVE`

* **用途**: **モデルの常駐時間**。最後の利用からの保持期間。
* **デフォルト**: `5m`
* **設定値**: 期間（例：`30s` / `10m` / `24h` / `0` / `-1`）
* **使用例**

  ```bash
  export OLLAMA_KEEP_ALIVE=10m   # 10分保持
  export OLLAMA_KEEP_ALIVE=0     # リクエスト毎に即アンロード
  export OLLAMA_KEEP_ALIVE=-1    # 無期限保持
  ```
* **シナリオ**: **再ロード待ちを減らす**（長め） / **メモリ節約**（短め）。
* **注意**: API リクエストで `keep_alive` を個別指定した場合は**そちらが優先**。

---

### `OLLAMA_KV_CACHE_TYPE`

* **用途**: 推論時の **K/V キャッシュの量子化方式**。
* **デフォルト**: `f16`
* **設定値**: `f32` / `f16` / `q8_0` / `q4_0`
* **使用例**

  ```bash
  export OLLAMA_KV_CACHE_TYPE=q8_0
  ```
* **シナリオ**: **長文**や**大モデル**で**メモリ節約**したい。
* **注意**: 低ビット量子化ほどメモリ節約大・**精度小影響**の可能性。
  モデル本体の量子化とは**独立**設定。

---

### `OLLAMA_MODELS`

* **用途**: **モデル保存ディレクトリ**の場所。
* **デフォルト**: OS 既定（例：`~/.ollama/models` など）
* **設定値**: ディレクトリパス
* **使用例**

  ```bash
  export OLLAMA_MODELS=/mnt/ssd/ollama-models
  ```
* **シナリオ**: 大容量ドライブに保存、複数ノードで同一ストレージを使う等。
* **注意**: 権限（Linux の service ユーザ）/既存モデル移行に留意。

---

### `OLLAMA_TMPDIR`

* **用途**: **一時ファイル**の保存先。
* **デフォルト**: OS の TEMP
* **設定値**: ディレクトリパス
* **使用例**

  ```bash
  export OLLAMA_TMPDIR=/var/tmp/ollama
  ```
* **シナリオ**: `/tmp` 容量不足回避、SSD を活用した高速ダウンロード。
* **注意**: 十分な空き容量を確保。

---

### `OLLAMA_NOPRUNE`

* **用途**: 起動時の**不要データ削除**（プルーニング）を無効化。
* **デフォルト**: 無効（クリーンアップする）
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_NOPRUNE=1
  ```
* **シナリオ**: 旧モデルを残したい / 起動時間短縮。
* **注意**: ディスクに**不要データ蓄積**。定期メンテ推奨。

---

## 3) ネットワーク／API

### `OLLAMA_HOST`

* **用途**: API サーバの**待受アドレス:ポート**。
* **デフォルト**: `127.0.0.1:11434`
* **設定値**: 例）`0.0.0.0:11434` / `192.168.1.10:11434`
* **使用例**

  ```bash
  export OLLAMA_HOST=0.0.0.0:11434
  ```
* **シナリオ**: LAN やコンテナ外部からアクセス可能にする。
* **注意**: 公開時は**認証/ファイアウォール/プロキシ**で保護を。

---

### `OLLAMA_ORIGINS`（CORS）

* **用途**: ブラウザからの **許可オリジン**（CORS）。
* **デフォルト**: ローカル系のみ許可
* **設定値**: 例）`https://example.com,http://app.local:3000` / `*`
* **使用例**

  ```bash
  export OLLAMA_ORIGINS=https://example.com,http://localhost:3000
  ```
* **シナリオ**: 別ドメインの Web フロントから API を叩く。
* **注意**: `*` は開放的すぎる。**必要最小限**に限定。

---

### `HTTPS_PROXY`（ダウンロード用）

* **用途**: モデル取得時に用いる **HTTPS プロキシ**。
* **デフォルト**: 未設定（直接続）
* **設定値**: 例）`https://user:pass@proxy.example.com:8443`
* **使用例**

  ```bash
  export HTTPS_PROXY=https://proxy.example.com:8443
  ```
* **シナリオ**: 社内ネットワークからインターネットへ出るときに必須。
* **注意**: `HTTP_PROXY` は通常**不要**（誤設定で不具合の元）。証明書要件に注意。

---

## 4) セキュリティ／プライバシー

### `OLLAMA_AUTH`

* **用途**: **API 認証**（Basic 等）を要求して無認証アクセスを遮断。
* **デフォルト**: 無効
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_AUTH=1
  ```
* **シナリオ**: サーバをネットワーク公開（LAN/外部）する。
* **注意**: 認証情報の配布・保護、HTTPS 化、プロキシ連携を検討。

---

### `OLLAMA_NOHISTORY`

* **用途**: 対話 CLI の**入力履歴を保存しない**。
* **デフォルト**: 無効（保存する）
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_NOHISTORY=1
  ```
* **シナリオ**: 機密プロンプトの漏えい対策、共有マシンでの配慮。
* **注意**: 使い勝手（履歴検索）とのトレードオフ。

---

## 5) ログ／デバッグ

### `OLLAMA_DEBUG`

* **用途**: **ログ詳細度**（0=INFO, 1=DEBUG, 2=TRACE）。
* **デフォルト**: `0`
* **設定値**: `0` / `1` / `2`
* **使用例**

  ```bash
  export OLLAMA_DEBUG=2
  ```
* **シナリオ**: 遅延/失敗時の**原因追跡**、バグ報告の添付ログ取得。
* **注意**: 2 はログ量が非常に多い。**一時的**に使用。

---

## 6) コンテキスト・ローディング・エンジン

### `OLLAMA_CONTEXT_LENGTH`

* **用途**: 既定の**コンテキスト長（トークン）**。
* **デフォルト**: `4096`（モデルにより差異あり）
* **設定値**: モデル上限内の整数（例：`8192` / `16384`）
* **使用例**

  ```bash
  export OLLAMA_CONTEXT_LENGTH=8192
  ```
* **シナリオ**: 長文を扱うワークロード（8K/16Kモデル運用）。
* **注意**: 値↑で RAM/VRAM 負荷↑・速度↓。モデル上限超は自動丸め/不安定化の恐れ。

---

### `OLLAMA_LOAD_TIMEOUT`

* **用途**: **モデル読み込み**のタイムアウト（ハング検知）。
* **デフォルト**: `5m`
* **設定値**: 期間（例：`30s` / `2m` / `0` / `-1`）
* **使用例**

  ```bash
  export OLLAMA_LOAD_TIMEOUT=2m
  ```
* **シナリオ**: 低速ストレージ・大モデルで時間延長／テストで短縮。
* **注意**: `0`/負は**無制限**。ハング時に復旧しないリスク。

---

### `OLLAMA_NEW_ENGINE`（実験的）

* **用途**: 開発中の**新エンジン**を使用。
* **デフォルト**: 無効
* **設定値**: `0` / `1`
* **使用例**

  ```bash
  export OLLAMA_NEW_ENGINE=1
  ```
* **シナリオ**: 新機能/最適化の検証。
* **注意**: 安定性未保証。本番は**十分な検証後**に。
